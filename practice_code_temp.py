import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e 
    

'''
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e 
        import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 4  # Healthy, Black Rot, Esca, Leaf Blight
INPUT_SHAPE = (*IMAGE_SIZE, 3)

# Data paths
DATA_DIR = 'data/grape_leaves'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
MODEL_PATH = 'models/grape_disease_detector.h5'

# Create directories if they don't exist
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)
os.makedirs('models', exist_ok=True)

class GrapeLeafDiseaseDetector:
    def __init__(self):
        self.model = None
        self.class_names = ['Healthy', 'Black Rot', 'Esca', 'Leaf Blight']
        self.history = None
        
    def load_data(self):
        """Load and preprocess the dataset"""
        print("Loading and preprocessing data...")
        
        # Data augmentation for training set
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # Only rescaling for validation and test sets
        test_datagen = ImageDataGenerator(rescale=1./255)
        
        # Training data generator
        self.train_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        # Validation data generator
        self.validation_generator = train_datagen.flow_from_directory(
            TRAIN_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
        
        # Test data generator
        self.test_generator = test_datagen.flow_from_directory(
            TEST_DIR,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
        
        print(f"Found {self.train_generator.samples} training images")
        print(f"Found {self.validation_generator.samples} validation images")
        print(f"Found {self.test_generator.samples} test images")
        
    def build_model(self):
        """Build the CNN model architecture"""
        print("Building model...")
        
        self.model = Sequential([
            # First convolutional block
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE),
            BatchNormalization(),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.2),
            
            # Second convolutional block
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.3),
            
            # Third convolutional block
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.4),
            
            # Fourth convolutional block
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu', padding='same'),
            BatchNormalization(),
            MaxPooling2D((2, 2)),
            Dropout(0.5),
            
            # Classifier
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(NUM_CLASSES, activation='softmax')
        ])
        
        optimizer = Adam(learning_rate=0.0001)
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model.summary()
    
    def train_model(self):
        """Train the model with callbacks"""
        print("Training model...")
        
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.1, patience=5),
            ModelCheckpoint(MODEL_PATH, save_best_only=True)
        ]
        
        self.history = self.model.fit(
            self.train_generator,
            steps_per_epoch=self.train_generator.samples // BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=self.validation_generator,
            validation_steps=self.validation_generator.samples // BATCH_SIZE,
            callbacks=callbacks
        )
    
    def evaluate_model(self):
        """Evaluate the model on test set"""
        print("Evaluating model...")
        
        # Load best saved model
        self.model = tf.keras.models.load_model(MODEL_PATH)
        
        # Evaluate on test set
        test_loss, test_acc = self.model.evaluate(self.test_generator)
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f}")
        
        # Generate predictions
        y_pred = self.model.predict(self.test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = self.test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=self.class_names))
        
        # Confusion matrix
        self.plot_confusion_matrix(y_true, y_pred_classes)
        
        # Plot training history
        self.plot_training_history()
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.class_names, 
                    yticklabels=self.class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix.png')
        plt.close()
    
    def plot_training_history(self):
        """Plot training and validation accuracy/loss"""
        if self.history is None:
            return
            
        plt.figure(figsize=(12, 4))
        
        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Training and Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('results/training_history.png')
        plt.close()
    
    def predict_disease(self, image_path):
        """Predict disease from a single image"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
            
        # Load and preprocess image
        img = Image.open(image_path)
        img = img.resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = self.model.predict(img_array)
        predicted_class = np.argmax(predictions)
        confidence = np.max(predictions)
        
        return {
            'class': self.class_names[predicted_class],
            'confidence': float(confidence),
            'all_predictions': {name: float(pred) for name, pred in zip(self.class_names, predictions[0])}
        }
    
    def save_model(self, path):
        """Save the trained model"""
        self.model.save(path)
        print(f"Model saved to {path}")
    
    def load_saved_model(self, path):
        """Load a pre-trained model"""
        self.model = tf.keras.models.load_model(path)
        print(f"Model loaded from {path}")

class DataPreprocessor:
    """Helper class for data preparation and organization"""
    @staticmethod
    def organize_dataset(raw_data_dir, output_dir, test_size=0.2):
        """
        Organize raw dataset into train/test directories with class subfolders
        """
        os.makedirs(output_dir, exist_ok=True)
        train_dir = os.path.join(output_dir, 'train')
        test_dir = os.path.join(output_dir, 'test')
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        # Define class names (adjust based on your dataset)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        for class_name in classes:
            # Create class directories in train and test
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
            
            # Get all images for this class
            class_dir = os.path.join(raw_data_dir, class_name)
            if not os.path.exists(class_dir):
                continue
                
            images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            # Split into train/test
            train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)
            
            # Copy images to appropriate directories
            for img in train_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(train_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
            for img in test_images:
                src = os.path.join(class_dir, img)
                dst = os.path.join(test_dir, class_name, img)
                if not os.path.exists(dst):
                    os.symlink(src, dst)  # or copy file for actual files
                    
        print(f"Dataset organized into {train_dir} and {test_dir}")

def main():
    # Example workflow
    
    # Step 1: Organize the dataset (only needed once)
    # raw_data_path = 'path/to/raw/grape/leaves'
    # DataPreprocessor.organize_dataset(raw_data_path, 'data/grape_leaves')
    
    # Step 2: Initialize and train the model
    detector = GrapeLeafDiseaseDetector()
    detector.load_data()
    detector.build_model()
    detector.train_model()
    detector.evaluate_model()
    detector.save_model(MODEL_PATH)
    
    # Step 3: Example prediction
    # test_image = 'path/to/test/image.jpg'
    # prediction = detector.predict_disease(test_image)
    # print(f"Prediction: {prediction}")

if __name__ == "__main__":
    main()
    class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
class GradCAM:
    """Class for generating Grad-CAM visualizations to interpret model predictions"""
    def __init__(self, model, last_conv_layer_name):
        self.model = model
        self.last_conv_layer_name = last_conv_layer_name
        self.grad_model = self._build_grad_model()
    
    def _build_grad_model(self):
        """Build a model that maps the input image to the activations
        of the last conv layer and the output predictions"""
        grad_model = tf.keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.last_conv_layer_name).output, 
                    self.model.output]
        )
        return grad_model
    
    def _compute_heatmap(self, img_array, pred_index=None):
        """Compute the Grad-CAM heatmap for a specific prediction index"""
        with tf.GradientTape() as tape:
            last_conv_layer_output, preds = self.grad_model(img_array)
            if pred_index is None:
                pred_index = tf.argmax(preds[0])
            class_channel = preds[:, pred_index]
        
        grads = tape.gradient(class_channel, last_conv_layer_output)
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        
        last_conv_layer_output = last_conv_layer_output[0]
        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
        return heatmap.numpy()
    
    def visualize(self, img_path, output_path=None):
        """Generate and visualize Grad-CAM heatmap"""
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        preds = self.model.predict(img_array)
        pred_class = np.argmax(preds[0])
        
        heatmap = self._compute_heatmap(img_array, pred_class)
        
        plt.figure(figsize=(10, 5))
        
        # Original image
        plt.subplot(1, 2, 1)
        plt.imshow(img)
        plt.title(f"Original\nPredicted: {detector.class_names[pred_class]}")
        plt.axis('off')
        
        # Heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(img)
        plt.imshow(heatmap, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')
        
        if output_path:
            plt.savefig(output_path)
            plt.close()
        else:
            plt.show()

class FlaskApp:
    """Web application for grape leaf disease detection"""
    templates_dir = 'templates'
    static_dir = 'static'
    upload_dir = 'static/uploads'
    
    @staticmethod
    def create_app(model_path):
        from flask import Flask, render_template, request, jsonify
        import uuid
        
        app = Flask(__name__, template_folder=FlaskApp.templates_dir, static_folder=FlaskApp.static_dir)
        os.makedirs(FlaskApp.upload_dir, exist_ok=True)
        
        # Load the trained model
        detector = GrapeLeafDiseaseDetector()
        detector.load_saved_model(model_path)
        
        @app.route('/')
        def home():
            return render_template('index.html', classes=detector.class_names)
        
        @app.route('/predict', methods=['POST'])
        def predict():
            if 'file' not in request.files:
                return jsonify({'error': 'No file uploaded'}), 400
                
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No file selected'}), 400
                
            if file:
                # Save the uploaded file
                ext = file.filename.split('.')[-1]
                filename = f"{uuid.uuid4()}.{ext}"
                filepath = os.path.join(FlaskApp.upload_dir, filename)
                file.save(filepath)
                
                # Make prediction
                try:
                    result = detector.predict_disease(filepath)
                    
                    # Generate Grad-CAM visualization
                    grad_cam = GradCAM(detector.model, 'conv2d_3')
                    grad_cam_path = os.path.join(FlaskApp.upload_dir, f"gradcam_{filename}")
                    grad_cam.visualize(filepath, grad_cam_path)
                    
                    return jsonify({
                        'prediction': result,
                        'image_url': f"/static/uploads/{filename}",
                        'gradcam_url': f"/static/uploads/gradcam_{filename}"
                    })
                except Exception as e:
                    return jsonify({'error': str(e)}), 500
                    
        return app

class MobileApp:
    """Mobile application interface for the disease detector"""
    @staticmethod
    def create_tflite_model(keras_model_path, tflite_path):
        """Convert Keras model to TensorFlow Lite format for mobile deployment"""
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        tflite_model = converter.convert()
        
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLite model saved to {tflite_path}")
    
    @staticmethod
    def test_tflite_model(tflite_path, test_image_path):
        """Test the TFLite model with a sample image"""
        # Load TFLite model and allocate tensors
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Preprocess input image
        img = Image.open(test_image_path).resize(IMAGE_SIZE)
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Test the model
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        # Get prediction
        output_data = interpreter.get_tensor(output_details[0]['index'])
        predicted_class = np.argmax(output_data[0])
        confidence = np.max(output_data[0])
        
        return {
            'class': predicted_class,
            'confidence': float(confidence),
            'all_predictions': output_data[0].tolist()
        }

class PerformanceOptimizer:
    """Class for optimizing model performance"""
    @staticmethod
    def prune_model(keras_model_path, pruned_model_path, target_sparsity=0.5):
        """Apply magnitude-based pruning to the model"""
        print(f"Pruning model with target sparsity {target_sparsity}")
        
        # Load the model
        model = tf.keras.models.load_model(keras_model_path)
        
        # Define pruning parameters
        pruning_params = {
            'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(
                target_sparsity,
                begin_step=0,
                frequency=100
            )
        }
        
        # Apply pruning to the model
        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
        
        # Recompile the model
        pruned_model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Save the pruned model
        pruned_model.save(pruned_model_path)
        print(f"Pruned model saved to {pruned_model_path}")
        
        return pruned_model
    
    @staticmethod
    def quantize_model(keras_model_path, quantized_model_path):
        """Apply post-training quantization to the model"""
        print("Quantizing model...")
        
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model_path)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        quantized_model = converter.convert()
        
        with open(quantized_model_path, 'wb') as f:
            f.write(quantized_model)
        
        print(f"Quantized model saved to {quantized_model_path}")
        return quantized_model

class DatasetAugmenter:
    """Class for augmenting the dataset to improve model performance"""
    @staticmethod
    def augment_dataset(input_dir, output_dir, augmentations_per_image=5):
        """Apply data augmentation to increase dataset size"""
        print(f"Augmenting dataset from {input_dir} to {output_dir}")
        
        datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.7, 1.3],
            fill_mode='nearest'
        )
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Process each class directory
        for class_dir in os.listdir(input_dir):
            class_input_path = os.path.join(input_dir, class_dir)
            class_output_path = os.path.join(output_dir, class_dir)
            
            if not os.path.isdir(class_input_path):
                continue
                
            os.makedirs(class_output_path, exist_ok=True)
            
            # Process each image in the class directory
            for img_file in os.listdir(class_input_path):
                img_path = os.path.join(class_input_path, img_file)
                
                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    continue
                    
                img = Image.open(img_path)
                img_array = np.array(img)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Generate augmented images
                i = 0
                for batch in datagen.flow(img_array, batch_size=1):
                    augmented_img = Image.fromarray(batch[0].astype('uint8'))
                    augmented_img.save(os.path.join(
                        class_output_path,
                        f"aug_{i}_{img_file}"
                    ))
                    
                    i += 1
                    if i >= augmentations_per_image:
                        break
        
        print(f"Augmented dataset saved to {output_dir}")

class ModelEvaluator:
    """Class for comprehensive model evaluation"""
    @staticmethod
    def evaluate_all_metrics(model, test_generator):
        """Evaluate model on various metrics"""
        print("Running comprehensive evaluation...")
        
        # Basic evaluation
        loss, accuracy = model.evaluate(test_generator)
        print(f"Test Accuracy: {accuracy:.4f}")
        print(f"Test Loss: {loss:.4f}")
        
        # Predictions
        y_pred = model.predict(test_generator)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true = test_generator.classes
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))
        
        # Confusion matrix
        ModelEvaluator.plot_confusion_matrix(y_true, y_pred_classes, test_generator.class_indices)
        
        # ROC Curve (for binary classification)
        if len(test_generator.class_indices) == 2:
            ModelEvaluator.plot_roc_curve(y_true, y_pred[:, 1])
        
        # Precision-Recall Curve
        ModelEvaluator.plot_precision_recall_curve(y_true, y_pred)
    
    @staticmethod
    def plot_confusion_matrix(y_true, y_pred, class_indices):
        """Plot normalized confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', 
                    xticklabels=class_indices.keys(), 
                    yticklabels=class_indices.keys())
        plt.title('Normalized Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('results/confusion_matrix_normalized.png')
        plt.close()
    
    @staticmethod
    def plot_roc_curve(y_true, y_scores):
        """Plot ROC curve for binary classification"""
        from sklearn.metrics import roc_curve, auc
        
        fpr, tpr, _ = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.savefig('results/roc_curve.png')
        plt.close()
    
    @staticmethod
    def plot_precision_recall_curve(y_true, y_scores):
        """Plot precision-recall curve for each class"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        # For each class
        n_classes = y_scores.shape[1]
        precision = dict()
        recall = dict()
        average_precision = dict()
        
        for i in range(n_classes):
            precision[i], recall[i], _ = precision_recall_curve(y_true == i, y_scores[:, i])
            average_precision[i] = average_precision_score(y_true == i, y_scores[:, i])
        
        # Plot all precision-recall curves
        plt.figure(figsize=(8, 6))
        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
        
        for i, color in zip(range(n_classes), colors[:n_classes]):
            plt.plot(recall[i], precision[i], color=color, lw=2,
                     label=f'Class {i} (AP = {average_precision[i]:.2f})')
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc="lower left")
        plt.savefig('results/precision_recall_curve.png')
        plt.close()

class Deployment:
    """Class handling model deployment to various platforms"""
    @staticmethod
    def deploy_to_tensorflow_serving(model_path, serving_dir):
        """Deploy model to TensorFlow Serving"""
        print(f"Deploying model to TensorFlow Serving at {serving_dir}")
        
        # Create version directory
        version_dir = os.path.join(serving_dir, '1')
        os.makedirs(version_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, version_dir)
        
        print("Model deployed successfully. You can now start TensorFlow Serving with:")
        print(f"tensorflow_model_server --rest_api_port=8501 --model_name=grape_disease --model_base_path={serving_dir}")
    
    @staticmethod
    def deploy_to_aws_sagemaker(model_path, s3_bucket):
        """Package model for AWS SageMaker deployment"""
        print(f"Packaging model for AWS SageMaker deployment to {s3_bucket}")
        
        import tarfile
        from datetime import datetime
        
        # Create a temporary directory
        temp_dir = 'tmp_sagemaker'
        os.makedirs(temp_dir, exist_ok=True)
        
        # Save model in SavedModel format
        model = tf.keras.models.load_model(model_path)
        tf.saved_model.save(model, os.path.join(temp_dir, '1'))
        
        # Create model.tar.gz
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        tar_filename = f"grape-disease-model-{timestamp}.tar.gz"
        
        with tarfile.open(tar_filename, 'w:gz') as tar:
            tar.add(temp_dir, arcname='.')
        
        # Upload to S3 (requires AWS CLI configured)
        os.system(f"aws s3 cp {tar_filename} s3://{s3_bucket}/")
        
        # Clean up
        os.remove(tar_filename)
        os.system(f"rm -rf {temp_dir}")
        
        print(f"Model packaged as {tar_filename} and uploaded to s3://{s3_bucket}")
        print("You can now create a SageMaker endpoint using this model package.")

class DataCollector:
    """Class for collecting and labeling new data"""
    @staticmethod
    def capture_images(output_dir, class_name, num_images=100):
        """Capture images from webcam for a specific class"""
        import cv2
        
        class_dir = os.path.join(output_dir, class_name)
        os.makedirs(class_dir, exist_ok=True)
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise RuntimeError("Could not open webcam")
        
        print(f"Capturing {num_images} images for class '{class_name}'...")
        print("Press 'c' to capture, 'q' to quit")
        
        count = 0
        while count < num_images:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Display the frame
            cv2.imshow('Capture Images - Press "c" to capture, "q" to quit', frame)
            
            key = cv2.waitKey(1)
            if key == ord('q'):
                break
            elif key == ord('c'):
                # Save the captured image
                img_path = os.path.join(class_dir, f"{class_name}_{count}.jpg")
                cv2.imwrite(img_path, frame)
                print(f"Saved {img_path}")
                count += 1
        
        cap.release()
        cv2.destroyAllWindows()
        print(f"Captured {count} images for class '{class_name}'")
    
    @staticmethod
    def label_images(raw_dir, labeled_dir):
        """Interactive tool for labeling raw images"""
        import cv2
        
        os.makedirs(labeled_dir, exist_ok=True)
        classes = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
        # Create class directories
        for class_name in classes:
            os.makedirs(os.path.join(labeled_dir, class_name), exist_ok=True)
        
        # Get list of raw images
        images = [f for f in os.listdir(raw_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not images:
            print("No images found in raw directory")
            return
            
        # Create window
        cv2.namedWindow('Label Images', cv2.WINDOW_NORMAL)
        
        current_idx = 0
        while current_idx < len(images):
            img_path = os.path.join(raw_dir, images[current_idx])
            img = cv2.imread(img_path)
            
            if img is None:
                current_idx += 1
                continue
                
            # Display image and instructions
            cv2.putText(img, "1: Healthy, 2: Black Rot, 3: Esca, 4: Leaf Blight", 
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(img, "Left/Right: Navigate, Esc: Quit", 
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow('Label Images', img)
            
            key = cv2.waitKey(0)
            
            if key == 27:  # ESC
                break
            elif key == 81 or key == 2:  # Left arrow
                current_idx = max(0, current_idx - 1)
            elif key == 83 or key == 3:  # Right arrow
                current_idx += 1
            elif 49 <= key <= 52:  # 1-4
                class_idx = key - 49
                class_name = classes[class_idx]
                
                # Copy image to labeled directory
                dst_path = os.path.join(labeled_dir, class_name, images[current_idx])
                os.rename(img_path, dst_path)
                print(f"Labeled {images[current_idx]} as {class_name}")
                
                current_idx += 1
        
        cv2.destroyAllWindows()
        print("Labeling session ended")

class ActiveLearning:
    """Class for implementing active learning pipeline"""
    def __init__(self, model_path, unlabeled_dir, labeled_dir):
        self.model = tf.keras.models.load_model(model_path)
        self.unlabeled_dir = unlabeled_dir
        self.labeled_dir = labeled_dir
        self.class_names = ['Healthy', 'Black_Rot', 'Esca', 'Leaf_Blight']
        
    def get_most_uncertain_samples(self, num_samples=10):
        """Identify samples the model is most uncertain about"""
        # Get all unlabeled images
        image_paths = []
        for root, _, files in os.walk(self.unlabeled_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_paths.append(os.path.join(root, file))
        
        if not image_paths:
            print("No unlabeled images found")
            return []
        
        # Calculate uncertainty (entropy) for each image
        uncertainties = []
        for img_path in image_paths:
            img = Image.open(img_path).resize(IMAGE_SIZE)
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)
            
            preds = self.model.predict(img_array)[0]
            entropy = -np.sum(preds * np.log(preds + 1e-10))  # Add small value to avoid log(0)
            uncertainties.append((img_path, entropy))
        
        # Sort by uncertainty (highest first)
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        
        return [x[0] for x in uncertainties[:num_samples]]
    
    def label_samples_interactively(self, sample_paths):
        """Label the selected samples interactively"""
        print("Labeling uncertain samples...")
        
        # Create class directories if they don't exist
        for class_name in self.class_names:
            os.makedirs(os.path.join(self.labeled_dir, class_name), exist_ok=True)
        
        # Label each sample
        for img_path in sample_paths:
            img = Image.open(img_path)
            img.show()
            
            print(f"Image: {os.path.basename(img_path)}")
            print("Select class:")
            for i, class_name in enumerate(self.class_names):
                print(f"{i+1}. {class_name}")
            print("0. Skip")
            
            try:
                choice = int(input("Your choice: "))
                if 1 <= choice <= len(self.class_names):
                    class_name = self.class_names[choice-1]
                    dst_path = os.path.join(
                        self.labeled_dir, 
                        class_name, 
                        os.path.basename(img_path)
                    )
                    
                    # Move the image to the labeled directory
                    os.rename(img_path, dst_path)
                    print(f"Labeled as {class_name}")
                else:
                    print("Skipped")
            except ValueError:
                print("Invalid input, skipped")
            
            img.close()
    
    def active_learning_cycle(self, num_samples=10):
        """Complete active learning cycle"""
        # Get most uncertain samples
        uncertain_samples = self.get_most_uncertain_samples(num_samples)
        
        if not uncertain_samples:
            return False
        
        # Label samples
        self.label_samples_interactively(uncertain_samples)
        
        return True

# Additional utility functions
def plot_sample_images(generator, num_images=8):
    """Plot sample images from the generator"""
    images, labels = next(generator)
    plt.figure(figsize=(10, 10))
    
    for i in range(min(num_images, len(images))):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i])
        plt.title(list(generator.class_indices.keys())[np.argmax(labels[i])])
        plt.axis('off')
    
    plt.tight_layout()
    plt.savefig('results/sample_images.png')
    plt.close()

def check_dataset_balance(generator):
    """Check and plot class distribution in the dataset"""
    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}
    
    for _, labels in generator:
        for label in labels:
            class_idx = np.argmax(label)
            class_name = list(generator.class_indices.keys())[class_idx]
            class_counts[class_name] += 1
        
        if generator.batch_index == 0:
            break
    
    plt.figure(figsize=(8, 6))
    plt.bar(class_counts.keys(), class_counts.values())
    plt.title('Class Distribution in Dataset')
    plt.xlabel('Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('results/class_distribution.png')
    plt.close()
    
    return class_counts

def export_model_for_production(model_path, export_dir):
    """Export model with preprocessing for production"""
    # Create a new model with preprocessing
    input_layer = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
    
    # Resize to expected input size
    x = tf.keras.layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1])(input_layer)
    
    # Load the trained model
    base_model = tf.keras.models.load_model(model_path)
    
    # Connect the preprocessing to the base model
    outputs = base_model(x)
    
    # Create the final model
    production_model = tf.keras.Model(inputs=input_layer, outputs=outputs)
    
    # Save the production model
    os.makedirs(export_dir, exist_ok=True)
    production_model.save(export_dir)
    
    print(f"Production model exported to {export_dir}")

def benchmark_model(model_path, test_images_dir, num_runs=100):
    """Benchmark model performance on test images"""
    import time
    
    model = tf.keras.models.load_model(model_path)
    
    # Get test images
    image_paths = []
    for root, _, files in os.walk(test_images_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    
    if not image_paths:
        print("No test images found")
        return
    
    # Warm up
    img = Image.open(image_paths[0]).resize(IMAGE_SIZE)
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    _ = model.predict(img_array)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        img_path = image_paths[i % len(image_paths)]
        img = Image.open(img_path).resize(IMAGE_SIZE)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        _ = model.predict(img_array)
    
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    
    print(f"Average inference time over {num_runs} runs: {avg_time:.4f} seconds")
    print(f"FPS: {1/avg_time:.2f}")
    
    return avg_time

def create_api(model_path):
    """Create a FastAPI for the model"""
    from fastapi import FastAPI, File, UploadFile
    from fastapi.responses import JSONResponse
    import uvicorn
    
    app = FastAPI()
    detector = GrapeLeafDiseaseDetector()
    detector.load_saved_model(model_path)
    
    @app.post("/predict")
    async def predict(file: UploadFile = File(...)):
        try:
            # Save the uploaded file temporarily
            temp_path = f"temp_{file.filename}"
            with open(temp_path, "wb") as f:
                f.write(file.file.read())
            
            # Make prediction
            result = detector.predict_disease(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            return JSONResponse(content=result)
        except Exception as e:
            return JSONResponse(content={"error": str(e)}, status_code=500)
    
    @app.get("/")
    async def root():
        return {"message": "Grape Leaf Disease Detector API"}
    
    return app

def run_api(model_path, host="0.0.0.0", port=8000):
    """Run the FastAPI server"""
    app = create_api(model_path)
    uvicorn.run(app, host=host, port=port)

# Main execution
if __name__ == "__main__":
    # Initialize the detector
    detector = GrapeLeafDiseaseDetector()
    
    # Example workflow
    try:
        # Load and preprocess data
        detector.load_data()
        
        # Check dataset balance
        check_dataset_balance(detector.train_generator)
        
        # Plot sample images
        plot_sample_images(detector.train_generator)
        
        # Build and train model
        detector.build_model()
        detector.train_model()
        
        # Evaluate model
        detector.evaluate_model()
        
        # Save model
        detector.save_model(MODEL_PATH)
        
        # Example prediction
        test_image = "data/test_samples/grape_black_rot_1.jpg"
        if os.path.exists(test_image):
            prediction = detector.predict_disease(test_image)
            print(f"Prediction for {test_image}: {prediction}")
            
            # Generate Grad-CAM visualization
            grad_cam = GradCAM(detector.model, 'conv2d_3')
            grad_cam.visualize(test_image, "results/gradcam_example.png")
        
        # Export for production
        export_model_for_production(MODEL_PATH, "models/production")
        
        # Benchmark model
        benchmark_model(MODEL_PATH, TEST_DIR)
        
        # Create TFLite model for mobile
        MobileApp.create_tflite_model(MODEL_PATH, "models/grape_disease_detector.tflite")
        
        # Run API (uncomment to enable)
        # run_api(MODEL_PATH)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise e '''